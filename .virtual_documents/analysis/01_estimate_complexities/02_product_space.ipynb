# Our experimental complexities need to run over a network (Product Space)
# How to build a Product Space is far from trivial
# The following is inspired by the original Product Space of the Atlas but uses methods statistically more sound
import sys
import pandas as pd
import networkx as nx
sys.path.append("../..")
from libraries import backboning as bb


# The Product Space is based on the MCP_exp matrix
# We binarize it to be consistent with how we calculate complexities
# We start with RCA then later we'll do RPOP as well
mcp_exp = pd.read_csv("../../data/processed/mcp_exp.csv", sep = "\t", dtype = {"prod": str})
mcp_rca = pd.pivot_table(data = mcp_exp, index = "prod", columns = "exporter", values = "rca").fillna(0.0) >= 1
mcp_rca


# My backboning library requires a pandas dataframe that is not triangular, even if the network is undirected
# The adjacency matrix should be weighted with the count of common exporter for each products
# This is easily achieved via dot product
ps = mcp_rca.astype(int).dot(mcp_rca.astype(int).T)
ps = ps.unstack()
# The library wants the columns to be called src, trg, and nij (the latter is the weight column)
ps.index.names = ("src", "trg")
ps = ps.reset_index().rename(columns = {0: "nij"})
# Throw away self loops
ps = ps[ps["src"] != ps["trg"]]
# Throw away empty links (products pairs without co-exporters)
ps = ps[ps["nij"] > 0]
ps


# Calculate the backbone scores for each link using the noise corrected method
# Method described in https://arxiv.org/abs/1701.07336
ps_nc = bb.noise_corrected(ps, undirected = True, calculate_p_value = True)

# We need to find a reasonable threshold to say that an edge is statistically significant
# This is tricky because we also want every product to have at least a link
# and we also want the Product Space to be a single connected component

# First we start by saying that we only want links with a p-value < 0.01
ps_nc_bb = bb.thresholding(ps_nc, 0.99)
ps_nc_bb


# Now we need to keep track of all products that don't have a link and the number of connected components in the Product Space
products = set(mcp_exp["prod"])
G = nx.from_pandas_edgelist(ps_nc_bb, source = "src", target = "trg", edge_attr = ("nij", "score"))
missing_products = products - set(G.nodes)
G_comps = list(nx.connected_components(G))
print("Products without a link:")
print(missing_products)
print(f"Connected components: {len(G_comps)}")


# We keep adding edges until we have a single connected components and no product has zero links
while len(G_comps) > 1 or len(missing_products) > 0:
    # First we need to know in which component each node is
    node2comp = {}
    for node in products:
        for i, c in enumerate(G_comps):
            _ = [i for i, c in enumerate(G_comps) if node in c]
            if len(_) == 0:
                # Isolated nodes are in a component identifid by their own code
                node2comp[node] = node
            else:
                # Nodes in a component get the component id
                node2comp[node] = _[0]
    # Assign component id to the nodes
    ps_nc["comp_src"] = ps_nc["src"].map(node2comp)
    ps_nc["comp_trg"] = ps_nc["trg"].map(node2comp)
    # We pick the most significant edge that connects two nodes in different components
    # This unifies the two components and/or reduces the number of isolated nodes
    new_edge = ps_nc[ps_nc["comp_src"] != ps_nc["comp_trg"]].sort_values(by = "score").iloc[-1]
    # Add the edge to the Product Space
    G.add_edge(new_edge["src"], new_edge["trg"], nij = new_edge["nij"], score = new_edge["score"])
    # Update the stopping conditions
    G_comps = list(nx.connected_components(G))
    missing_products = products - set(G.nodes)
    print(f"Connected components: {len(G_comps)}, Missing product count: {len(missing_products)}")


# Now we have a Product Space with p < 0.01 edges, except the ones tying it together in a single component
# This is based on RCA, so let's name it accordingly
nx.write_edgelist(G, "ps_nc_bb_0.01_rca.csv", delimiter = "\t", data = ["nij", "score"])


# And now we do it all again, but for RPOP instead of RCA
# Maybe this should be a utility function
mcp_rpop = pd.pivot_table(data = mcp_exp, index = "prod", columns = "exporter", values = "rpop").fillna(0.0) >= 0.25

ps = mcp_rpop.astype(int).dot(mcp_rpop.astype(int).T)
ps = ps.unstack()
ps.index.names = ("src", "trg")
ps = ps.reset_index().rename(columns = {0: "nij"})
ps = ps[ps["src"] != ps["trg"]]
ps = ps[ps["nij"] > 0]

ps_nc = bb.noise_corrected(ps, undirected = True, calculate_p_value = True)

# We start with a much lower significance threshold (0.9 instead of 0.99)
# Because RPOP edges seem to be much more noisy...
ps_nc_bb = bb.thresholding(ps_nc, 0.9)

products = set(mcp_exp["prod"])
G = nx.from_pandas_edgelist(ps_nc_bb, source = "src", target = "trg", edge_attr = ("nij", "score"))
missing_products = products - set(G.nodes)
G_comps = list(nx.connected_components(G))

while len(G_comps) > 1 or len(missing_products) > 0:
    node2comp = {}
    for node in products:
        for i, c in enumerate(G_comps):
            _ = [i for i, c in enumerate(G_comps) if node in c]
            if len(_) == 0:
                node2comp[node] = node
            else:
                node2comp[node] = _[0]
    ps_nc["comp_src"] = ps_nc["src"].map(node2comp)
    ps_nc["comp_trg"] = ps_nc["trg"].map(node2comp)
    new_edge = ps_nc[ps_nc["comp_src"] != ps_nc["comp_trg"]].sort_values(by = "score").iloc[-1]
    G.add_edge(new_edge["src"], new_edge["trg"], nij = new_edge["nij"], score = new_edge["score"])
    G_comps = list(nx.connected_components(G))
    missing_products = products - set(G.nodes)
    print(f"Connected components: {len(G_comps)}, Missing product count: {len(missing_products)}")

nx.write_edgelist(G, "ps_nc_bb_0.1_rpop.csv", delimiter = "\t", data = ["nij", "score"])
